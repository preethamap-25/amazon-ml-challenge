{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvbJ4rXqs0PA"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle datasets download -d preethamaap/amazon-ml-challenge\n",
        "!unzip amazon-ml-challenge.zip -d /content/amazon_dataset\n"
      ],
      "metadata": {
        "id": "JJf7cBdws3yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import os\n"
      ],
      "metadata": {
        "id": "-8i0gaMCt0zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EcomDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, tokenizer, max_len=128, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = str(row['catalog_content'])\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Read image from Kaggle dataset folder\n",
        "        img_path = os.path.join(self.img_dir, row['image_link'])  # image_link contains file name\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        price = torch.tensor(row['price'], dtype=torch.float) if 'price' in row else torch.tensor(0.0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'image': img,\n",
        "            'price': price\n",
        "        }\n"
      ],
      "metadata": {
        "id": "HhXxPwYKt2C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "O-4wMaVKt4GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/amazon_dataset/train.csv')  # Adjust if using test.csv\n",
        "img_dir = '/content/amazon_dataset/images'  # Kaggle images folder\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "dataset = EcomDataset(df, img_dir, tokenizer, transform=image_transform)\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
      ],
      "metadata": {
        "id": "L20y8p2zt5aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from transformers import AutoModel\n",
        "\n",
        "class MultiModalRegressor(nn.Module):\n",
        "    def __init__(self, text_model_name='distilbert-base-uncased'):\n",
        "        super().__init__()\n",
        "        self.text_model = AutoModel.from_pretrained(text_model_name)\n",
        "        self.text_hidden_size = self.text_model.config.hidden_size\n",
        "\n",
        "        self.image_model = models.resnet50(pretrained=True)\n",
        "        self.image_model.fc = nn.Identity()  # Remove classification layer\n",
        "        self.image_hidden_size = 2048\n",
        "\n",
        "        self.fc1 = nn.Linear(self.text_hidden_size + self.image_hidden_size, 512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(512,1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, image):\n",
        "        text_out = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_feat = text_out.last_hidden_state[:,0,:]  # CLS token\n",
        "\n",
        "        image_feat = self.image_model(image)\n",
        "\n",
        "        combined = torch.cat([text_feat, image_feat], dim=1)\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        out = self.fc2(x)\n",
        "        return out.squeeze(1)\n"
      ],
      "metadata": {
        "id": "wbNTg4Drt34S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiModalRegressor().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "epochs = 3  # Increase as needed\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        images = batch['image'].to(device)\n",
        "        prices = batch['price'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask, images)\n",
        "        loss = criterion(outputs, prices)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "tSJf6vrgt86I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'multi_modal_model.pth')\n"
      ],
      "metadata": {
        "id": "us9dasqet-lS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}