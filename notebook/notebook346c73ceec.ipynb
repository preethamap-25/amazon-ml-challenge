{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13364130,"sourceType":"datasetVersion","datasetId":8476543}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.applications import ResNet50, resnet50\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom tqdm import tqdm\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:08:16.976279Z","iopub.execute_input":"2025-10-13T10:08:16.976720Z","iopub.status.idle":"2025-10-13T10:08:16.993673Z","shell.execute_reply.started":"2025-10-13T10:08:16.976689Z","shell.execute_reply":"2025-10-13T10:08:16.992685Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\n\n# Paths to CSVs (read-only)\nTRAIN_CSV = \"/kaggle/input/ml-challenge-dataset/dataset/train.csv\"   # path to your training CSV\nTEST_CSV = \"/kaggle/input/ml-challenge-dataset/dataset/test.csv\"     # path to your test CSV\n\n# Training images (read-only)\nDOWNLOAD_DIR_TRAIN = \"/kaggle/input/ml-challenge-dataset/images/images\"\n\n# Writable directory for test images (to be downloaded later)\nWORKING_DIR = \"/kaggle/working/ml-challenge-dataset\"\nDOWNLOAD_DIR_TEST = os.path.join(WORKING_DIR, \"test_images\")\n\n# Create writable directory for test images\nos.makedirs(DOWNLOAD_DIR_TEST, exist_ok=True)\n\n# Model/training parameters\nIMG_SIZE = (224, 224)\nKFOLDS = 3\nEPOCHS = 3\nBATCH_SIZE = 32\n\nprint(\"‚úÖ Setup complete.\")\nprint(f\"Training images (read-only): {DOWNLOAD_DIR_TRAIN}\")\nprint(f\"Test images (writable): {DOWNLOAD_DIR_TEST}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:05:50.716536Z","iopub.execute_input":"2025-10-13T10:05:50.716908Z","iopub.status.idle":"2025-10-13T10:05:50.724890Z","shell.execute_reply.started":"2025-10-13T10:05:50.716881Z","shell.execute_reply":"2025-10-13T10:05:50.723596Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Setup complete.\nTraining images (read-only): /kaggle/input/ml-challenge-dataset/images/images\nTest images (writable): /kaggle/working/ml-challenge-dataset/test_images\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def download_image(url, save_path):\n    try:\n        if not os.path.exists(save_path):\n            response = requests.get(url, timeout=10)\n            if response.status_code == 200:\n                img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n                img.save(save_path, \"JPEG\", quality=90)\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Failed: {url} ‚Äî {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:06:57.818360Z","iopub.execute_input":"2025-10-13T10:06:57.819248Z","iopub.status.idle":"2025-10-13T10:06:57.825640Z","shell.execute_reply.started":"2025-10-13T10:06:57.819204Z","shell.execute_reply":"2025-10-13T10:06:57.824399Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df.columns = [c.strip().lower() for c in train_df.columns]\ntrain_df[\"filepath\"] = train_df[\"sample_id\"].apply(lambda x: os.path.join(DOWNLOAD_DIR_TRAIN, f\"{x}.jpg\"))\n\n# üì• Download missing training images\nprint(\"üì• Checking and downloading missing training images...\")\nfor _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n    if not os.path.exists(row[\"filepath\"]):\n        download_image(row[\"image_link\"], row[\"filepath\"])\n\ntrain_df = train_df[train_df[\"filepath\"].apply(os.path.exists)].reset_index(drop=True)\nprint(f\"‚úÖ {len(train_df)} training images ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:08:24.408491Z","iopub.execute_input":"2025-10-13T10:08:24.408868Z","iopub.status.idle":"2025-10-13T10:12:49.102213Z","shell.execute_reply.started":"2025-10-13T10:08:24.408838Z","shell.execute_reply":"2025-10-13T10:12:49.101176Z"}},"outputs":[{"name":"stdout","text":"üì• Checking and downloading missing training images...\n","output_type":"stream"},{"name":"stderr","text":" 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 38999/75000 [02:02<1:29:18,  6.72it/s]","output_type":"stream"},{"name":"stdout","text":"‚ö†Ô∏è Failed: https://m.media-amazon.com/images/I/51mjZYDYjyL.jpg ‚Äî HTTPSConnectionPool(host='m.media-amazon.com', port=443): Max retries exceeded with url: /images/I/51mjZYDYjyL.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7d64019e5490>: Failed to resolve 'm.media-amazon.com' ([Errno -3] Temporary failure in name resolution)\"))\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75000/75000 [03:30<00:00, 356.73it/s] \n","output_type":"stream"},{"name":"stdout","text":"‚úÖ 74999 training images ready.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ==================================================\n# üî¢ PRICE SCALING\n# ==================================================\nscaler = MinMaxScaler()\ntrain_df[\"price_scaled\"] = scaler.fit_transform(train_df[[\"price\"]])\njoblib.dump(scaler, \"price_scaler.pkl\")\n\n# ==================================================\n# üì∏ IMAGE DATA GENERATORS\n# ==================================================\ndatagen_train = ImageDataGenerator(\n    preprocessing_function=resnet50.preprocess_input,\n    rotation_range=25,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\ndatagen_val = ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:13:07.932782Z","iopub.execute_input":"2025-10-13T10:13:07.933185Z","iopub.status.idle":"2025-10-13T10:13:07.946536Z","shell.execute_reply.started":"2025-10-13T10:13:07.933153Z","shell.execute_reply":"2025-10-13T10:13:07.945473Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def build_model():\n    base_model = ResNet50(weights=None, include_top=False, input_shape=(224,224,3))\n    base_model.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.4),\n        layers.Dense(64, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(1)\n    ])\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                  loss='mse', metrics=['mae'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:25:47.378421Z","iopub.execute_input":"2025-10-13T10:25:47.378844Z","iopub.status.idle":"2025-10-13T10:25:47.385782Z","shell.execute_reply.started":"2025-10-13T10:25:47.378782Z","shell.execute_reply":"2025-10-13T10:25:47.384722Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# ==================================================\n# üîÑ K-FOLD CROSS VALIDATION\n# ==================================================\nkf = KFold(n_splits=KFOLDS, shuffle=True, random_state=42)\nfold = 1\nfold_scores = []\n\nfor train_idx, val_idx in kf.split(train_df):\n    print(f\"\\nüåÄ Training Fold {fold}/{KFOLDS}\")\n    train_data = train_df.iloc[train_idx]\n    val_data = train_df.iloc[val_idx]\n\n    train_gen = datagen_train.flow_from_dataframe(\n        dataframe=train_data,\n        x_col=\"filepath\",\n        y_col=\"price_scaled\",\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        class_mode=\"raw\"\n    )\n\n    val_gen = datagen_val.flow_from_dataframe(\n        dataframe=val_data,\n        x_col=\"filepath\",\n        y_col=\"price_scaled\",\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        class_mode=\"raw\",\n        shuffle=False\n    )\n\n    model = build_model()\n\n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4, min_lr=1e-6),\n        ModelCheckpoint(f\"best_model_fold{fold}.h5\", save_best_only=True, monitor='val_loss')\n    ]\n\n    # Phase 1 ‚Äî Train with frozen base\n    model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    # Phase 2 ‚Äî Fine-tuning last 30 layers\n    model.layers[0].trainable = True\n    for layer in model.layers[0].layers[:-30]:\n        layer.trainable = False\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n                  loss='mse', metrics=['mae'])\n\n    model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=10,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    val_loss, val_mae = model.evaluate(val_gen)\n    fold_scores.append((val_loss, val_mae))\n    print(f\"‚úÖ Fold {fold} MAE: {val_mae:.4f}\")\n    fold += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T10:25:51.268957Z","iopub.execute_input":"2025-10-13T10:25:51.269802Z"}},"outputs":[{"name":"stdout","text":"\nüåÄ Training Fold 1/3\nFound 49999 validated image filenames.\nFound 25000 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n\u001b[1m  48/1563\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m1:08:19\u001b[0m 3s/step - loss: 2.5192 - mae: 1.0215","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n# ==================================================\n# üìà FINAL RESULTS\n# ==================================================\navg_loss = np.mean([l for l, _ in fold_scores])\navg_mae  = np.mean([m for _, m in fold_scores])\nprint(f\"\\nüéØ Average Validation Loss: {avg_loss:.4f}, MAE: {avg_mae:.4f}\")\nprint(\"‚úÖ Training completed successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================================================\n# üß™ TESTING ‚Äî PRICE PREDICTION ON TEST DATASET\n# ==================================================\nprint(\"\\nüß™ Loading test dataset...\")\ntest_df = pd.read_csv(TEST_CSV)\ntest_df.columns = [c.strip().lower() for c in test_df.columns]\ntest_df[\"filepath\"] = test_df[\"sample_id\"].apply(lambda x: os.path.join(DOWNLOAD_DIR_TEST, f\"{x}.jpg\"))\n\n# üì• Download test images\nfor _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    if not os.path.exists(row[\"filepath\"]):\n        download_image(row[\"image_link\"], row[\"filepath\"])\n\ntest_df = test_df[test_df[\"filepath\"].apply(os.path.exists)].reset_index(drop=True)\nprint(f\"‚úÖ {len(test_df)} test images ready for prediction.\")\n\n# Use best model (from last fold)\nbest_model_path = f\"best_model_fold{KFOLDS}.h5\"\nmodel = tf.keras.models.load_model(best_model_path)\n\n# Preprocess test images and predict\nX_test = np.array([\n    resnet50.preprocess_input(img_to_array(load_img(p, target_size=IMG_SIZE)))\n    for p in tqdm(test_df[\"filepath\"], desc=\"üßÆ Preprocessing test images\")\n])\n\ny_pred_scaled = model.predict(X_test)\nscaler = joblib.load(\"price_scaler.pkl\")\ny_pred = scaler.inverse_transform(y_pred_scaled)\n\n# Save predictions\ntest_df[\"predicted_price\"] = y_pred\ntest_df[[\"sample_id\", \"predicted_price\"]].to_csv(\"predicted_prices.csv\", index=False)\nprint(\"üíæ Predictions saved to predicted_prices.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}